{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fb4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "#for the 2nd part\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "#for the 3rd part\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadb994-9632-416f-ac27-f35acc558568",
   "metadata": {},
   "source": [
    "## Part One: Data Analysis and Bayes Nets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dab9000-1a0d-4236-943d-99cb6580501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the images\n",
    "img = np.load(\"smiley_dataset/smiley_X.npy\")#noiseless dataset\n",
    "img2 = np.load(\"smiley_dataset/smiley_noisy_X.npy\") #noisy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf65915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the classes\n",
    "cls = np.load(\"smiley_dataset/smiley_Y.npy\") #class for noiseless Dataset\n",
    "cls2 = np.load(\"smiley_dataset/smiley_noisy_Y.npy\") #Class for noisy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d2b480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (204, 9, 9, 1)\n",
      "Images2 shape: (204, 9, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Images shape:\", img.shape) #printing the noiseless dataset\n",
    "print(\"Images2 shape:\", img2.shape)#printing the noisy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc0630",
   "metadata": {},
   "source": [
    "# the shape of the dataset as printed above, tells it is a 4-dimensional numpy array with 204 samples, 9 height, 9 width and 1 channel(implying a grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb247525-e2df-4dba-bff6-9e4c70f7910d",
   "metadata": {},
   "source": [
    "# preprocessing the dataset\n",
    "\n",
    "The following process is to ensure that each imput parameter(pixel) has similar data distribution to fasten covergence while training and also not to affect output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab0ef46-79b6-4147-b600-e268d3da4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(img.min())\n",
    "print(img.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cda354-c3cf-44e6-868d-eeec5ac56d0f",
   "metadata": {},
   "source": [
    "#The output gotten inidicates that it's fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c747996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0.0 Count: 72\n",
      "Class: 1.0 Count: 60\n",
      "Class: 2.0 Count: 72\n",
      "\n",
      " for noisy dataset \n",
      "\n",
      "Class: 0.0 Count: 72\n",
      "Class: 1.0 Count: 60\n",
      "Class: 2.0 Count: 72\n"
     ]
    }
   ],
   "source": [
    "#verifying the number of unique classes with their corresponding leabels\n",
    "# Get the unique classes and their counts\n",
    "unique_classes, class_counts = np.unique(cls, return_counts=True)\n",
    "# Print the unique classes and their counts\n",
    "for class_label, count in zip(unique_classes, class_counts):\n",
    "    print(\"Class:\", class_label, \"Count:\", count)\n",
    "    \n",
    "print(\"\\n for noisy dataset \\n\")    \n",
    "unique_noisy_classes, noisy_class_counts = np.unique(cls2, return_counts=True)\n",
    "# Print the unique classes and their counts\n",
    "for noisy_class_label, count in zip(unique_noisy_classes, noisy_class_counts):\n",
    "    print(\"Class:\", noisy_class_label, \"Count:\", count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb853db",
   "metadata": {},
   "source": [
    "# the result from the above cell indicates that both the noisy and noiseless dataset contain 72 images, 60 images and 72 images which belong to sad, neutral and happpy respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03f2d53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Selecting some random from the noisy dataset for visualization\n",
    "indices = np.random.choice(len(img2), size=5, replace=False)\n",
    "\n",
    "# Ploting the selected images \n",
    "fig, axes = plt.subplots(1, len(indices), figsize=(10, 4))\n",
    "for i, index in enumerate(indices):\n",
    "    axes[i].imshow(img[index, :, :, 0], cmap='gray')\n",
    "    axes[i].set_title(f\"Class: {cls2[index]}\")\n",
    "    axes[i].axis('off')#turning off axis labels for cleaner display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e785bc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Selecting some random indices from the noiseless dataset for visualization\n",
    "indices = np.random.choice(len(img), size=5, replace=False)\n",
    "\n",
    "# Ploting the selected images\n",
    "fig, axes = plt.subplots(1, len(indices), figsize=(10, 4))\n",
    "for i, index in enumerate(indices):\n",
    "    axes[i].imshow(img[index, :, :, 0], cmap='gray')\n",
    "    axes[i].set_title(f\"Class: {cls[index]}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc8801",
   "metadata": {},
   "source": [
    "#Results from the two cell above show visualization of 5 random images from the datasets(noiseless and noisy) which seem to match their corresponding classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d1ee8-9af1-4059-9c45-56863e751d6f",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea33db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the datasets into training and testing sets\n",
    "img_train, img_test, cl_train, cl_test = train_test_split(img, cls, test_size=0.2, random_state=42)\n",
    "#img_noisy_train, img_noisy_test, cl_noisy_train, cl_noisy_test = train_test_split(img2, cls2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3786d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Naïve Bayes classifier\n",
    "naive_bayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e746eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier on the training sets\n",
    "naive_bayes.fit(img_train.reshape(img_train.shape[0], -1), cl_train)\n",
    "#naive_bayes.fit(img_noisy_train.reshape(img_noisy_train.shape[0], -1), cl_noisy_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "449f30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the testing set to match the input format\n",
    "img_test_reshaped = img_test.reshape(img_test.shape[0], -1)\n",
    "#img_noisy_test_reshaped = img_noisy_test.reshape(img_noisy_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32bea04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the testing set\n",
    "cl_pred = naive_bayes.predict(img_test_reshaped)\n",
    "#cl_noisy_pred = naive_bayes.predict(img_noisy_test_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924d9168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6585365853658537\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculating and printing the accuracy\n",
    "accuracy = accuracy_score(cl_test, cl_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f472d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f770ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[10  4  1]\n",
      " [ 1  6  2]\n",
      " [ 0  6 11]]\n"
     ]
    }
   ],
   "source": [
    "# Generating  and printing the confusion matrix\n",
    "confusion_mat = confusion_matrix(cl_test, cl_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d83c449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP Rate: 0.8571428571428571\n",
      "FP Rate: 0.2857142857142857\n",
      "Precision: 0.6\n",
      "Recall: 0.8571428571428571\n",
      "F Measure: 0.7058823529411764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate and print TP rate, FP rate, precision, recall, and F measure\n",
    "tp_rate = confusion_mat[1, 1] / (confusion_mat[1, 1] + confusion_mat[1, 0])\n",
    "fp_rate = confusion_mat[0, 1] / (confusion_mat[0, 1] + confusion_mat[0, 0])\n",
    "precision = confusion_mat[1, 1] / (confusion_mat[1, 1] + confusion_mat[0, 1])\n",
    "recall = tp_rate\n",
    "f_measure = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(\"TP Rate:\", tp_rate)\n",
    "print(\"FP Rate:\", fp_rate)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F Measure:\", f_measure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1402ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f4d4ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Area: 0.8387867647058823\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print ROC area\n",
    "if len(unique_classes) == 2:  # Binary classification\n",
    "    roc_area = roc_auc_score(cl_test, cl_pred)\n",
    "else:  # Multi-class classification\n",
    "    cl_prob = naive_bayes.predict_proba(img_test_reshaped)\n",
    "    roc_area = roc_auc_score(cl_test, cl_prob, multi_class='ovr')\n",
    "print(\"ROC Area:\", roc_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ceffde",
   "metadata": {},
   "source": [
    "# Discusion for the metrics\n",
    "from the results of the metrics calculated above,\n",
    "Accuracy of 0.5853658536585366 suggests that 58.54% samples were correctly classified\n",
    "True Positive Rate of 0.75 indicates that 75% of the images were identified correctly\n",
    "False Positive Rate of 0.42857142857142855 implies that 42% of the times it avoids misclassifying negative samples as positive\n",
    "Precision of 0.5 means that the classifier has made a 50% positive prediction of correct classification. This also means that the classifier's positive predictions are not very reliable\n",
    "Recall(also True Positive) of 75% incicates that the classifier is reasonably good at identifying positive samples\n",
    "F-Measure: The score of 60% suggests that the classifier's precision and recall are somehow on a balanced scale.\n",
    "Confusion Matrix: It can be seen from the result of the confusion matrix that true positives(diagonal figures), false positives and false negatives(off-diagonal figures) for each class implying that class 0(sad) has 8 true positives, 6 false positives, and 1 false negative.\n",
    "ROC value of 0.8387 suggests that the classifier performs quite well and can effectively differentiate between the classes, and it has a reasonably good discriminatory power.\n",
    "\n",
    "In the nutshell, the results indicate that the classifier performs relatively well in identifying Class 2 samples, with a high recall and precision. However, it faces challenges in correctly distinguishing between Class 0 and Class 1, as shown by the relatively low precision and recall for these classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48729f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c6e3eb2-211c-45c2-8114-b2177f4046fe",
   "metadata": {},
   "source": [
    "# Part Two: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e64ce-2414-40cd-b05b-aed0e2a0a385",
   "metadata": {},
   "source": [
    "# kMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "641ca8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART TWO BEGINS HERE\n",
    "img_2d = img.reshape(img.shape[0], -1) #reshaping the images array from 4d to 2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b75a73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = len(np.unique(cls))\n",
    "#instance of the KMeans clustering algorithm\n",
    "kmeans = KMeans(n_clusters=num_clusters, n_init=10, init='k-means++', random_state=42)\n",
    "\n",
    "# Fiting k means to the dataset\n",
    "cluster_lbl = kmeans.fit(img_2d).labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96bae9-1828-4d51-b19d-7468f47250b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cd93e9d-e72b-435c-9abb-f9afd4e7bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans Clustering Accuracy: 0.17647058823529413\n"
     ]
    }
   ],
   "source": [
    "#evaluating the accuracy of the clustering\n",
    "km_accuracy = accuracy_score(cls, cluster_lbl)\n",
    "print(f\"Kmeans Clustering Accuracy: {km_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3e0cb39-f8aa-4af1-9a59-d358786f57e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'permutations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m             best_matching \u001b[38;5;241m=\u001b[39m permuted_labels\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_matching\n\u001b[1;32m---> 17\u001b[0m best_matching_labels \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_lbl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Calculate clustering accuracy\u001b[39;00m\n\u001b[0;32m     20\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(\u001b[38;5;28mcls\u001b[39m, best_matching_labels)\n",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m, in \u001b[0;36mfind_best_matching\u001b[1;34m(true_labels, cluster_lbl)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_best_matching\u001b[39m(true_labels, cluster_lbl):\n\u001b[1;32m----> 4\u001b[0m     true_perm \u001b[38;5;241m=\u001b[39m \u001b[43mpermutations\u001b[49m(np\u001b[38;5;241m.\u001b[39munique(true_labels))\n\u001b[0;32m      5\u001b[0m     best_matching \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     max_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'permutations' is not defined"
     ]
    }
   ],
   "source": [
    "#using the Hungarian algorithm\n",
    "\n",
    "def find_best_matching(true_labels, cluster_lbl):\n",
    "    true_perm = permutations(np.unique(true_labels))\n",
    "    best_matching = None\n",
    "    max_accuracy = -1\n",
    "    for perm in true_perm:\n",
    "        permuted_labels = np.zeros_like(true_labels)\n",
    "        for i, label in enumerate(np.unique(true_labels)):\n",
    "            permuted_labels[true_labels == label] = perm[i]\n",
    "        accuracy = accuracy_score(permuted_labels, cluster_lbl)\n",
    "        if accuracy > max_accuracy:\n",
    "            max_accuracy = accuracy\n",
    "            best_matching = permuted_labels\n",
    "    return best_matching\n",
    "\n",
    "best_matching_labels = find_best_matching(cls, cluster_lbl)\n",
    "\n",
    "# Calculate clustering accuracy\n",
    "accuracy = accuracy_score(cls, best_matching_labels)\n",
    "print(\"Kmeans Clustering Accuracy using Hungarian:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd80d1-e57f-479e-80ed-d5e183eb21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting a visualization of the cluster for centroid clusters\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(num_clusters):\n",
    "    cluster_images = img[cluster_lbl == i]\n",
    "    for j in range(min(10, cluster_images.shape[0])):\n",
    "        plt.subplot(num_clusters, 10, i * 10 + j + 1)\n",
    "        plt.imshow(cluster_images[j].squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        if j == 0:\n",
    "            plt.title(f'Cluster {i}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0f1a5-1121-487e-a087-0b70669f393b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3e8ed-643a-465c-b390-2990fcad968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "unique_clusters = np.unique(cluster_lbl)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_clusters)))\n",
    "\n",
    "for i, cluster in enumerate(unique_clusters):\n",
    "    plt.scatter(img_2d[cluster_labels == cluster, 0], img_2d[cluster_lbl == cluster, 1], color=colors[i], label=f'Cluster {cluster}')\n",
    "\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=100, c='black', marker='x', label='Centroids')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('K-means Clustering of Smiley Dataset')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b27b9-9d90-4ede-a77a-33d01eea2bbb",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "from the result gotten when kmeans clustering was run on the dataset. it is observed that the accuracy of the default kmeans algorithm is very low while that gotten from using the Hungarian algorithhm on the kmeans was a bit high but still poor. The improvement in accuracy using the hungarian algorithm is because it takes into consideration the classes and tries to find the bes alignment between the two sets while the default kmeans approach assumes a direct correspondence between the cluster labels and the class labels.\n",
    "The result gotten from visualizing the cluster show how images are grouped according to their corresponding cluster. The show that the cluster has tried to show these images in their best centroids even though some images appear to be a bit off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b5de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE# Step 2: Perform PCA (Dimensionality Reduction)\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(img_2d)\n",
    "# Step 3: Perform t-SNE (Dimensionality Reduction)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(img_2d)\n",
    "\n",
    "# Step 4: Visualize PCA and t-SNE results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(pca_result[:, 0], pca_result[:, 1], c=cls, cmap='viridis')\n",
    "plt.title('PCA Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=cls, cmap='viridis')\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters\n",
    "num_clusters = len(np.unique(cls))\n",
    "\n",
    "# Step 2: Perform K-means (Hard Clustering)\n",
    "\n",
    "kmeans_cluster_labels = cluster_lbl\n",
    "\n",
    "# Step 3: Perform Gaussian Mixture Model (GMM) with EM (Soft Clustering)\n",
    "gmm = GaussianMixture(n_components=num_clusters, random_state=42)\n",
    "gmm_cluster_labels = gmm.fit_predict(img_2d)\n",
    "\n",
    "# Step 4: Perform Agglomerative Hierarchical Clustering (Soft Clustering)\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "agg_cluster_labels = agg_clustering.fit_predict(img_2d)\n",
    "\n",
    "# Step 5: Compare the performance of clustering algorithms\n",
    "kmeans_accuracy = accuracy_score(cls, kmeans_cluster_labels)\n",
    "gmm_adjusted_rand_score = adjusted_rand_score(cls, gmm_cluster_labels)\n",
    "agg_adjusted_rand_score = adjusted_rand_score(cls, agg_cluster_labels)\n",
    "\n",
    "print(\"K-means Accuracy:\", kmeans_accuracy)\n",
    "print(\"GMM Adjusted Rand Score:\", gmm_adjusted_rand_score)\n",
    "print(\"Agglomerative Hierarchical Clustering Adjusted Rand Score:\", agg_adjusted_rand_score)\n",
    "\n",
    "# Step 6: Visualize the clusters\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.scatter(img_2d[:, 0], img_2d[:, 1], c=kmeans_cluster_labels, cmap='viridis')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=100, c='black', marker='x')\n",
    "plt.title('K-means Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.scatter(img_2d[:, 0], img_2d[:, 1], c=gmm_cluster_labels, cmap='viridis')\n",
    "plt.title('GMM with EM Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(img_2d[:, 0], img_2d[:, 1], c=agg_cluster_labels, cmap='viridis')\n",
    "plt.title('Agglomerative Hierarchical Clustering')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09f37d-9aef-4acf-acf1-39213870a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reduce the dimensionality using t-SNE for visualization (optional)\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_result = tsne.fit_transform(img_2d)\n",
    "\n",
    "# Step 3: Perform K-means (Hard Clustering) on the 2D data\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42)\n",
    "kmeans_cluster_labels = kmeans.fit_predict(img_2d)\n",
    "\n",
    "# Step 4: Perform Gaussian Mixture Model (GMM) with EM (Soft Clustering) on the 2D data\n",
    "gmm = GaussianMixture(n_components=3, init_params='kmeans', random_state=42)\n",
    "gmm_cluster_labels = gmm.fit_predict(img_2d)\n",
    "\n",
    "# Step 5: Perform Agglomerative Hierarchical Clustering (Soft Clustering) on the 2D data\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=3)\n",
    "agg_cluster_labels = agg_clustering.fit_predict(img_2d)\n",
    "\n",
    "# Step 6: Evaluate the performance of clustering algorithms\n",
    "kmeans_accuracy = accuracy_score(cls, kmeans_cluster_labels)\n",
    "gmm_adjusted_rand_score = adjusted_rand_score(cls, gmm_cluster_labels)\n",
    "agg_adjusted_rand_score = adjusted_rand_score(cls, agg_cluster_labels)\n",
    "\n",
    "print(\"K-means Accuracy:\", kmeans_accuracy)\n",
    "print(\"GMM Adjusted Rand Score:\", gmm_adjusted_rand_score)\n",
    "print(\"Agglomerative Hierarchical Clustering Adjusted Rand Score:\", agg_adjusted_rand_score)\n",
    "\n",
    "# Step 7: Visualize the clustering results (2D data) along with true class labels (optional)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=cls, cmap='viridis')\n",
    "plt.title('True Class Labels (t-SNE)')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=kmeans_cluster_labels, cmap='viridis')\n",
    "plt.title('K-means Clustering (t-SNE)')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=gmm_cluster_labels, cmap='viridis')\n",
    "plt.title('GMM with EM Clustering (t-SNE)')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e406f-8139-4190-a742-d301273b0f08",
   "metadata": {},
   "source": [
    "# Discusion\n",
    "from the results of the plotted clusters above, it appears that the dataset does not respond well to clusters. It shows the dots consistenly located in the same spots for all clusters which suggests that algorithms are not able to find distinct clusters in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate the ARI between the cluster labels and the ground truth labels\n",
    "kmeans_ari = adjusted_rand_score(cls, cluster_labels)\n",
    "print(\"Adjusted Rand Index (ARI):\", kmeans_ari)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72e8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implemeningt NMI for Kmeans clustering\n",
    "kmeans_nmi = normalized_mutual_info_score(cls, cluster_labels)\n",
    "#print the NMI score\n",
    "print(\"NMI SCORe:\", kmeans_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the scores for K-means\n",
    "kmeans_scores = {\n",
    "    \"ARI\": kmeans_ari,\n",
    "    \"NMI\": kmeans_nmi\n",
    "}\n",
    "evaluation_scores.append((\"K-means\", kmeans_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c9118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing EM cLustering using GMM\n",
    "\n",
    "# Create an instance of the GaussianMixture algorithm\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "\n",
    "# Fit the GMM to the data\n",
    "gmm.fit(images_2d)\n",
    "\n",
    "# Get the cluster labels\n",
    "gmm_labels = gmm.predict(img_2d)\n",
    "\n",
    "# Calculate the ARI for the GMM clustering\n",
    "gmm_ari = adjusted_rand_score(cls, gmm_labels)\n",
    "\n",
    "# Print the ARI score\n",
    "print(\"Adjusted Rand Index (ARI):\", gmm_ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa64560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implemeningt NMI for GMM clustering\n",
    "gmm_nmi = normalized_mutual_info_score(cls, gmm_labels)\n",
    "#print the NMI score\n",
    "print(\"NMI SCORE:\", gmm_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f27d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the scores for GMM\n",
    "gmm_scores = {\n",
    "    \"ARI\": gmm_ari,\n",
    "    \"NMI\": gmm_nmi\n",
    "}\n",
    "evaluation_scores.append((\"GMM\", gmm_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing Hierarchical Clustering\n",
    "# Create an instance of the AgglomerativeClustering algorithm\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3)\n",
    "\n",
    "# Fit the hierarchical clustering algorithm to the data\n",
    "hierarchical.fit(img_2d)\n",
    "\n",
    "# Get the cluster labels\n",
    "hierarchical_labels = hierarchical.labels_\n",
    "# Calculate the ARI for the hierarchical clustering\n",
    "hierarchical_ari = adjusted_rand_score(cls, hierarchical_labels)\n",
    "print(\"Evaluation Metric Score:\", hierarchical_ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implemeningt NMI for HIERARCHICAL clustering\n",
    "hierarchical_nmi = normalized_mutual_info_score(cls, hierarchical_labels)\n",
    "#print the NMI score\n",
    "print(\"NMI SCORE:\", hierarchical_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the scores for Hierarchical clustering\n",
    "hierarchical_scores = {\n",
    "    \"ARI\": hierarchical_ari,\n",
    "    \"NMI\": hierarchical_nmi\n",
    "}\n",
    "evaluation_scores.append((\"Hierarchical\", hierarchical_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fa299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the scores for K-means\n",
    "kmeans_scores = evaluation_scores[0][1]\n",
    "kmeans_ari = kmeans_scores[\"ARI\"]\n",
    "kmeans_nmi = kmeans_scores[\"NMI\"]\n",
    "print(kmeans_ari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996661c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff58248e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check the number of unique labels\n",
    "num_unique_labels = len(set(cls))\n",
    "if num_unique_labels < 2:\n",
    "    print(\"Error: Number of unique labels is less than 2. Unable to compute evaluation metrics.\")\n",
    "else:\n",
    "    # Loop over different numbers of clusters\n",
    "    for num_clusters in range(2, 10):\n",
    "        # K-means\n",
    "        kmeans = KMeans(n_clusters=num_clusters,n_init=10, random_state=42)\n",
    "        kmeans.fit(images_2d)\n",
    "        kmeans_labels = kmeans.labels_\n",
    "        kmeans_silhouette = silhouette_score(img_2d, kmeans_labels)\n",
    "        kmeans_ari = adjusted_rand_score(cls, kmeans_labels)\n",
    "        kmeans_nmi = normalized_mutual_info_score(cls, kmeans_labels)\n",
    "        print(f\"K-means: Number of Clusters: {num_clusters}\\t Silhouette Score: {kmeans_silhouette}\\t ARI: {kmeans_ari}\\t NMI Score:{kmeans_nmi}\")\n",
    "        \n",
    "        #Em clustering using GMM\n",
    "        gmm = GaussianMixture(n_components = 3, random_state=42)\n",
    "        gmm.fit(images_2d)\n",
    "        gmm_labels = gmm.predict(images_2d)\n",
    "        gmm_silhouette =  silhouette_score(img_2d, gmm_labels)\n",
    "        gmm_ari = adjusted_rand_score(cls, gmm_labels)\n",
    "        print(f\"EM Clustering: Number of Clusters: {num_clusters}\\t Silhouette Score: {gmm_silhouette}\\t ARI: {gmm_ari}\")\n",
    "        \n",
    "        \n",
    "        # Hierarchical clustering\n",
    "        hierarchical = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "        hierarchical.fit(img_2d)\n",
    "        hierarchical_labels = hierarchical.labels_\n",
    "        hierarchical_silhouette = silhouette_score(img_2d, hierarchical_labels)\n",
    "        hierarchical_ari = adjusted_rand_score(cls, hierarchical_labels)\n",
    "        print(f\"Hierarchical Clustering: Number of Clusters: {num_clusters}\\t Silhouette Score: {hierarchical_silhouette}\\t ARI: {hierarchical_ari}\\n \")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of algorithm names and evaluation scores\n",
    "algorithm_names, scores = zip(*evaluation_scores)\n",
    "\n",
    "# Get the evaluation metric names (e.g., ARI, NMI)\n",
    "metric_names = list(evaluation_scores[0][1].keys())\n",
    "\n",
    "# Set the position of the bars on the x-axis\n",
    "x = np.arange(len(algorithm_names))\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Create subplots for each evaluation metric\n",
    "fig, ax = plt.subplots()\n",
    "for i, metric_name in enumerate(metric_names):\n",
    "    # Calculate the position of each bar\n",
    "    pos = x + (i - len(metric_names) / 2) * bar_width\n",
    "\n",
    "    # Get the scores for the current evaluation metric\n",
    "    metric_scores = [score[1][metric_name] for score in evaluation_scores]\n",
    "\n",
    "    # Plot the bars for the current evaluation metric\n",
    "    ax.bar(pos, metric_scores, bar_width, label=metric_name)\n",
    "\n",
    "# Set the x-axis labels and tick positions\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithm_names)\n",
    "plt.xlabel('Clustering Algorithm')\n",
    "plt.ylabel('Evaluation Metric Score')\n",
    "plt.title('Comparison of Clustering Algorithms')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe860385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check the number of unique labels\n",
    "num_unique_labels = len(set(cls))\n",
    "if num_unique_labels < 2:\n",
    "    print(\"Error: Number of unique labels is less than 2. Unable to compute evaluation metrics.\")\n",
    "else:\n",
    "    # Define the range of clusters to explore\n",
    "    num_clusters_range = range(2, 10)\n",
    "\n",
    "    # Initialize lists to store evaluation metric scores\n",
    "    kmeans_silhouette_scores = []\n",
    "    kmeans_ari_scores = []\n",
    "    kmeans_nmi_scores=[]\n",
    "    gmm_silhouette_scores = []\n",
    "    gmm_ari_scores = []\n",
    "    gmm_nmi_scores=[]\n",
    "    hierarchical_silhouette_scores = []\n",
    "    hierarchical_ari_scores = []\n",
    "    hierarchical_nmi_scores=[]\n",
    "\n",
    "    # Loop over different numbers of clusters\n",
    "    for num_clusters in num_clusters_range:\n",
    "        # K-means\n",
    "        kmeans = KMeans(n_clusters=num_clusters,n_init=10, random_state=42)\n",
    "        kmeans.fit(images_2d)\n",
    "        kmeans_labels = kmeans.labels_\n",
    "        kmeans_silhouette = silhouette_score(img_2d, kmeans_labels)\n",
    "        kmeans_ari = adjusted_rand_score(cls, kmeans_labels)\n",
    "        kmeans_nmi = normalized_mutual_info_score(cls, kmeans_labels)\n",
    "        kmeans_silhouette_scores.append(kmeans_silhouette)\n",
    "        kmeans_ari_scores.append(kmeans_ari)\n",
    "        kmeans_nmi_scores.append(kmeans_nmi)\n",
    "\n",
    "        # EM clustering using GMM\n",
    "        gmm = GaussianMixture(n_components=num_clusters, random_state=42)\n",
    "        gmm.fit(images_2d)\n",
    "        gmm_labels = gmm.predict(img_2d)\n",
    "        gmm_silhouette = silhouette_score(img_2d, gmm_labels)\n",
    "        gmm_ari = adjusted_rand_score(cls, gmm_labels)\n",
    "        gmm_nmi = normalized_mutual_info_score(cls, gmm_labels)\n",
    "        gmm_silhouette_scores.append(gmm_silhouette)\n",
    "        gmm_ari_scores.append(gmm_ari)\n",
    "        gmm_nmi_scores.append(gmm_nmi)\n",
    "\n",
    "        # Hierarchical clustering\n",
    "        hierarchical = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "        hierarchical.fit(images_2d)\n",
    "        hierarchical_labels = hierarchical.labels_\n",
    "        hierarchical_silhouette = silhouette_score(img_2d, hierarchical_labels)\n",
    "        hierarchical_ari = adjusted_rand_score(cls, hierarchical_labels)\n",
    "        hierarchical_nmi = normalized_mutual_info_score(cls, hierarchical_labels)\n",
    "        hierarchical_silhouette_scores.append(hierarchical_silhouette)\n",
    "        hierarchical_ari_scores.append(hierarchical_ari)\n",
    "        hierarchical_nmi_scores.append(hierarchical_nmi)\n",
    "\n",
    "    # Visualize Silhouette Scores\n",
    "    plt.plot(num_clusters_range, kmeans_silhouette_scores, label='K-means')\n",
    "    plt.plot(num_clusters_range, gmm_silhouette_scores, label='GMM')\n",
    "    plt.plot(num_clusters_range, hierarchical_silhouette_scores, label='Hierarchical')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.legend()\n",
    "    plt.title('Silhouette Scores for Different Clustering Algorithms')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize ARI Scores\n",
    "    plt.plot(num_clusters_range, kmeans_ari_scores, label='K-means')\n",
    "    plt.plot(num_clusters_range, gmm_ari_scores, label='GMM')\n",
    "    plt.plot(num_clusters_range, hierarchical_ari_scores, label='Hierarchical')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Adjusted Rand Index (ARI)')\n",
    "    plt.legend()\n",
    "    plt.title('Adjusted Rand Index (ARI) for Different Clustering Algorithms')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize NMI Scores\n",
    "    plt.plot(num_clusters_range, kmeans_nmi_scores, label='K-means')\n",
    "    plt.plot(num_clusters_range, gmm_nmi_scores, label='GMM')\n",
    "    plt.plot(num_clusters_range, hierarchical_nmi_scores, label='Hierarchical')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Normalized Mutual Info (NMI)')\n",
    "    plt.legend()\n",
    "    plt.title('Normalized Mutual Info (NMI) for Different Clustering Algorithms')\n",
    "    plt.show()\n",
    "\n",
    "    # Draw Conclusions\n",
    "    best_kmeans_num_clusters = num_clusters_range[kmeans_silhouette_scores.index(max(kmeans_silhouette_scores))]\n",
    "    best_gmm_num_clusters = num_clusters_range[gmm_silhouette_scores.index(max(gmm_silhouette_scores))]\n",
    "    best_hierarchical_num_clusters = num_clusters_range[hierarchical_silhouette_scores.index(max(hierarchical_silhouette_scores))]\n",
    "    \n",
    "    print(f\"Best number of clusters for K-means: {best_kmeans_num_clusters}\")\n",
    "    print(f\"Best number of clusters for GMM: {best_gmm_num_clusters}\")\n",
    "    print(f\"Best number of clusters for Hierarchical: {best_hierarchical_num_clusters}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee63d8-6928-49a0-ade3-c9ecee28e2e2",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "it is observed from the result gotten that the best cluster for the k-mean is 7, that for GMM is 4 and that for hierarchical is 7. This indicates how the k-means clustering and Hierarchical are similar in handling this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd07f7-9192-420d-bb28-b19567b2687b",
   "metadata": {},
   "source": [
    "## Part 3: Supervised Learning: Generalisation & Overfitting; Decision trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05566157",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1596126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the input features\n",
    "num_samples, image_height, image_width, num_channels = img_train.shape\n",
    "X_train_reshaped = img_train.reshape(num_samples, image_height * image_width * num_channels)\n",
    "\n",
    "k = 10  # Number of folds for cross-validation\n",
    "scores = cross_val_score(clf, X_train_reshaped, Y_train, cv=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a3df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy scores for each fold:\")\n",
    "print(scores)\n",
    "print(\"Mean accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the training set\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Reshape the test set\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Create an instance of DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the decision tree classifier to the training data\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Use the fitted classifier to predict the labels for the test set\n",
    "y_pred = clf.predict(X_test_reshaped)\n",
    "\n",
    "# Calculate the accuracy of the classifier's predictions on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e04f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd22ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34172384",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95225c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Experiment with different parameters\n",
    "parameters = [\n",
    "    {\"max_depth\": 3},\n",
    "    {\"min_impurity_decrease\": 0.01},\n",
    "    {\"criterion\": \"entropy\"},\n",
    "    {\"min_samples_leaf\": 5},\n",
    "    {\"ccp_alpha\": 0.1}\n",
    "]\n",
    "\n",
    "# Loop over the parameters\n",
    "for params in parameters:\n",
    "    # Set the parameters for the classifier\n",
    "    clf.set_params(**params)\n",
    "\n",
    "    # Fit the classifier on the training set\n",
    "    clf.fit(X_train_reshaped, y_train)\n",
    "\n",
    "    # Predict on the training set and calculate metrics\n",
    "    y_train_pred = clf.predict(X_train_reshaped)\n",
    "    train_confusion_mat = confusion_matrix(y_train, y_train_pred)\n",
    "    train_TP = train_confusion_mat[1, 1]\n",
    "    train_FP = train_confusion_mat[0, 1]\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='macro')\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='macro')\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "\n",
    "    # Predict on the test set and calculate metrics\n",
    "    y_test_pred = clf.predict(X_test_reshaped)\n",
    "    test_confusion_mat = confusion_matrix(y_test, y_test_pred)\n",
    "    test_TP = test_confusion_mat[1, 1]\n",
    "    test_FP = test_confusion_mat[0, 1]\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Parameters:\", params)\n",
    "    print(\"Training Set:\")\n",
    "    print(\"Accuracy:\", train_accuracy)\n",
    "    print(\"Precision:\", train_precision)\n",
    "    print(\"Recall:\", train_recall)\n",
    "    print(\"TP:\", train_TP)\n",
    "    print(\"FP:\", train_FP)\n",
    "    print(\"F1 Score:\", train_f1)\n",
    "    print(\"Test Set:\")\n",
    "    print(\"Accuracy:\", test_accuracy)\n",
    "    print(\"Precision:\", test_precision)\n",
    "    print(\"Recall:\", test_recall)\n",
    "    print(\"TP:\", test_TP)\n",
    "    print(\"FP:\", test_FP)\n",
    "    print(\"F1 Score:\", test_f1)\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7372b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following cell contains the requirement for the 5th sub-part of the 3rd prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848360bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping the imput data to have two dimensions\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Create a new training set and testing set with 30% instances in the testing set\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_train_reshaped,y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the decision tree classifier on the new training set\n",
    "clf.fit(X_train_new, y_train_new)\n",
    "\n",
    "# Evaluate accuracy on the training set\n",
    "y_train_pred_new = clf.predict(X_train_new)\n",
    "train_accuracy_new = accuracy_score(y_train_new, y_train_pred_new)\n",
    "\n",
    "# Evaluate accuracy on the testing set\n",
    "y_test_pred_new = clf.predict(X_test_new)\n",
    "test_accuracy_new = accuracy_score(y_test_new, y_test_pred_new)\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies for 30% instances in testing set:\")\n",
    "print(\"Training Accuracy:\", train_accuracy_new)\n",
    "print(\"Testing Accuracy:\", test_accuracy_new)\n",
    "\n",
    "# Create a new training set and testing set with 60% instances in the testing set\n",
    "X_train_new2, X_test_new2, y_train_new2, y_test_new2 = train_test_split(X_train_reshaped, y_train, test_size=0.6, random_state=42)\n",
    "\n",
    "# Fit the decision tree classifier on the new training set\n",
    "clf.fit(X_train_new2, y_train_new2)\n",
    "\n",
    "# Evaluate accuracy on the training set\n",
    "y_train_pred_new2 = clf.predict(X_train_new2)\n",
    "train_accuracy_new2 = accuracy_score(y_train_new2, y_train_pred_new2)\n",
    "\n",
    "# Evaluate accuracy on the testing set\n",
    "y_test_pred_new2 = clf.predict(X_test_new2)\n",
    "test_accuracy_new2 = accuracy_score(y_test_new2, y_test_pred_new2)\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Accuracies for 60% instances in testing set:\")\n",
    "print(\"Training Accuracy:\", train_accuracy_new2)\n",
    "print(\"Testing Accuracy:\", test_accuracy_new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e80734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#random forest clasifier\n",
    "\n",
    "#reshaping the imput data to have two dimensions\n",
    "images_train_reshaped = images.reshape(images.shape[0], -1)\n",
    "images_test_reshaped = images_test.reshape(images_test.shape[0], -1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_train_reshaped,classes,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c3a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a5a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(images_train_reshaped, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7956b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_rf = rf_classifier.predict(images_train_reshaped)\n",
    "train_accuracy_rf = accuracy_score(classes, y_train_pred_rf)\n",
    "train_precision_rf = precision_score(classes, y_train_pred_rf, average='macro')\n",
    "train_recall_rf = recall_score(classes, y_train_pred_rf, average='macro')\n",
    "train_f1_rf = f1_score(classes, y_train_pred_rf, average='macro')\n",
    "# Evaluate other metrics as required\n",
    "\n",
    "y_test_pred_rf = rf_classifier.predict(images_test_reshaped)\n",
    "test_accuracy_rf = accuracy_score(classes, y_test_pred_rf)\n",
    "test_precision_rf = precision_score(y_test, y_test_pred_rf, average='macro')\n",
    "test_recall_rf = recall_score(y_test, y_test_pred_rf, average='macro')\n",
    "test_f1_rf = f1_score(y_test, y_test_pred_rf, average='macro')\n",
    "# Evaluate other metrics as required\n",
    "\n",
    "# Print the results\n",
    "print(\"Random Forest Classifier - Original Training Set:\")\n",
    "print(\"Accuracy:\", train_accuracy_rf)\n",
    "print(\"Precision:\", train_precision_rf)\n",
    "print(\"Recall:\", train_recall_rf)\n",
    "print(\"F1 Score:\", train_f1_rf)\n",
    "\n",
    "print(\"Random Forest Classifier - Test Set:\")\n",
    "print(\"Accuracy:\", test_accuracy_rf)\n",
    "print(\"Precision:\", test_precision_rf)\n",
    "print(\"Recall:\", test_recall_rf)\n",
    "print(\"F1 Score:\", test_f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba34d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reshape the input data to have two dimensions\n",
    "images_train_reshaped = images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_train_reshaped, classes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and calculate metrics\n",
    "y_train_pred_rf = rf_classifier.predict(X_train)\n",
    "train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n",
    "train_precision_rf = precision_score(y_train, y_train_pred_rf, average='macro')\n",
    "train_recall_rf = recall_score(y_train, y_train_pred_rf, average='macro')\n",
    "train_f1_rf = f1_score(y_train, y_train_pred_rf, average='macro')\n",
    "train_confusion_matrix_rf = confusion_matrix(y_train, y_train_pred_rf)\n",
    "train_tp_rf = train_confusion_matrix_rf.diagonal()\n",
    "train_fp_rf = train_confusion_matrix_rf.sum(axis=0) - train_tp_rf\n",
    "\n",
    "# Predict on the test set and calculate metrics\n",
    "y_test_pred_rf = rf_classifier.predict(X_test)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "test_precision_rf = precision_score(y_test, y_test_pred_rf, average='macro')\n",
    "test_recall_rf = recall_score(y_test, y_test_pred_rf, average='macro')\n",
    "test_f1_rf = f1_score(y_test, y_test_pred_rf, average='macro')\n",
    "test_confusion_matrix_rf = confusion_matrix(y_test, y_test_pred_rf)\n",
    "test_tp_rf = test_confusion_matrix_rf.diagonal()\n",
    "test_fp_rf = test_confusion_matrix_rf.sum(axis=0) - test_tp_rf\n",
    "\n",
    "# Print the results\n",
    "print(\"Random Forest Classifier - Training Set:\")\n",
    "print(\"Accuracy:\", train_accuracy_rf)\n",
    "print(\"Precision:\", train_precision_rf)\n",
    "print(\"Recall:\", train_recall_rf)\n",
    "print(\"F1 Score:\", train_f1_rf)\n",
    "print(\"TP:\", train_tp_rf)\n",
    "print(\"FP:\", train_fp_rf)\n",
    "\n",
    "print(\"Random Forest Classifier - Test Set:\")\n",
    "print(\"Accuracy:\", test_accuracy_rf)\n",
    "print(\"Precision:\", test_precision_rf)\n",
    "print(\"Recall:\", test_recall_rf)\n",
    "print(\"F1 Score:\", test_f1_rf)\n",
    "print(\"TP:\", test_tp_rf)\n",
    "print(\"FP:\", test_fp_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is for the 4th part of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f144ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Reshape the input data to have two dimensions\n",
    "images_train_reshaped = images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_train_reshaped, classes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0766b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear classifier\n",
    "linear_clf = LinearRegression()\n",
    "\n",
    "# Fit the classifier on the training set\n",
    "linear_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and calculate accuracy\n",
    "y_train_pred_linear = linear_clf.predict(X_train)\n",
    "train_accuracy_linear = accuracy_score(y_train, y_train_pred_linear.round())\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_test_pred_linear = linear_clf.predict(X_test)\n",
    "test_accuracy_linear = accuracy_score(y_test, y_test_pred_linear.round())\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Linear Classifier - Training Set (without cross-validation):\")\n",
    "print(\"Accuracy:\", train_accuracy_linear)\n",
    "\n",
    "print(\"Linear Classifier - Test Set (without cross-validation):\")\n",
    "print(\"Accuracy:\", test_accuracy_linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7235e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear classifier\n",
    "linear_clf_cv = LinearRegression()\n",
    "\n",
    "# Perform cross-validation and calculate the accuracies\n",
    "cv_scores = cross_val_score(linear_clf_cv, X_train, y_train, cv=10)\n",
    "cv_accuracy_mean = cv_scores.mean()\n",
    "\n",
    "# Print the cross-validation accuracy\n",
    "print(\"Linear Classifier - Cross-Validation Accuracy:\")\n",
    "print(\"Mean Accuracy:\", cv_accuracy_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1023582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp_clf = MLPClassifier(max_iter =500)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (100, 50, 100)],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation to find the best parameters\n",
    "grid_search = GridSearchCV(mlp_clf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best MLP classifier\n",
    "best_params = grid_search.best_params_\n",
    "best_mlp_clf = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best MLP classifier on the training set\n",
    "best_mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training set and calculate accuracy\n",
    "y_train_pred_mlp = best_mlp_clf.predict(X_train)\n",
    "train_accuracy_mlp = accuracy_score(y_train, y_train_pred_mlp)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_test_pred_mlp = best_mlp_clf.predict(X_test)\n",
    "test_accuracy_mlp = accuracy_score(y_test, y_test_pred_mlp)\n",
    "\n",
    "# Print the results\n",
    "print(\"Multilayer Perceptron (MLP) - Best Parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "print(\"Multilayer Perceptron (MLP) - Training Set:\")\n",
    "print(\"Accuracy:\", train_accuracy_mlp)\n",
    "\n",
    "print(\"Multilayer Perceptron (MLP) - Test Set:\")\n",
    "print(\"Accuracy:\", test_accuracy_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "#Defining the image size\n",
    "img_width = 100\n",
    "img_height = 100\n",
    "img_channels = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Resize the images to (100, 100)\n",
    "images_train_resized = [resize(img, (100, 100)) for img in images_train]\n",
    "\n",
    "# Convert the resized images to a numpy array and add a channel dimension\n",
    "images_train_reshaped = np.array(images_train_resized).reshape(-1, 100, 100, 1)\n",
    "\n",
    "\n",
    "print(\"train image reshaped size\",images_train_reshaped.shape)\n",
    "print(\"test image reshaped size\",images_test_reshaped.shape)\n",
    "\n",
    "images_train_reshaped = images_train_reshaped.reshape(-1, 100, 100, 1)\n",
    "images_test_reshaped = images_test_reshaped.reshape(-1, 100, 100, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_train_categorical = classes\n",
    "# Define and compile the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, img_channels)))\n",
    "cnn_model.add(MaxPooling2D((2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(images_train_reshaped, y_train_categorical, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the CNN model on the test set\n",
    "test_loss, test_accuracy_cnn = cnn_model.evaluate(images_test_reshaped, y_test_categorical)\n",
    "\n",
    "# Print the test accuracy for CNN\n",
    "print(\"Convolutional Neural Network (CNN) - Test Set Accuracy:\")\n",
    "print(\"Accuracy:\", test_accuracy_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22034e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eef4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the images\n",
    "resized_images_for_CNN = [resize(img, (100,100)) for img in images]\n",
    "print(\"Resized images shape:\", resized_images_for_CNN[0].shape)\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "images_CNN_train, images_CNN_test, classes_CNN_train, classes_CNN_test = train_test_split(resized_images_for_CNN, classes, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ff7ef-264d-4504-b9f4-650928eb7b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 100\n",
    "img_height = 100\n",
    "img_channels = 1\n",
    "num_classes = len(np.unique(classes))\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, img_channels)))\n",
    "cnn_model.add(MaxPooling2D((2, 2)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(num_classes, activation='softmax'))\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17677825-529a-43b7-8d9f-2f3c704d31e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting test labels to one-hot encoded format\n",
    "\n",
    "classes_test_categorical = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Check the number of samples in the test set (images_CNN_test and classes_test_categorical)\n",
    "print(\"Number of samples in images_CNN_test:\", len(images_CNN_test))\n",
    "print(\"Number of samples in classes_test_categorical:\", len(classes_test_categorical))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy_cnn = cnn_model.evaluate(np.array(images_CNN_test), classes_test_categorical)\n",
    "\n",
    "print(\"Convolutional Neural Network (CNN) - Test Set Accuracy:\")\n",
    "print(\"Accuracy:\", test_accuracy_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c96d0-9e54-4d14-9d5c-f0f125da06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy_cnn = cnn_model.evaluate(images_CNN_test, y_test_onehot)\n",
    "\n",
    "# Print the test accuracy for CNN\n",
    "print(\"Convolutional Neural Network (CNN) - Test Set Accuracy:\")\n",
    "print(\"Accuracy:\", test_accuracy_cnn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
